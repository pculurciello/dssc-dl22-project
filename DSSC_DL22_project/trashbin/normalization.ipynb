{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9417d9",
   "metadata": {},
   "source": [
    "https://inside-machinelearning.com/en/why-and-how-to-normalize-data-object-detection-on-image-in-pytorch-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae890b51",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "First of all we will load the data we need.\n",
    "\n",
    "We use for that the datasets module.\n",
    "\n",
    "Itâ€™s a module integrated to PyTorch that allows to quickly load datasets. Ideal to practice coding !\n",
    "\n",
    "The dataset that interests us is called CIFAR-10. It is composed of 60 000 images in RGB color and size 32Ã—32.\n",
    "They are divided into 10 classes (plane, automobile, bird, cat, deer, dog, frog, horse, boat, truck), with 6 000 images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e715a56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /app/One-Class-Audio-Classifier/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /app/One-Class-Audio-Classifier/cifar10/cifar-10-python.tar.gz to /app/One-Class-Audio-Classifier/cifar10\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'cifar10')\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.ToTensor()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9ee61",
   "metadata": {},
   "source": [
    "# Verifying the data\n",
    "\n",
    "Letâ€™s be a bit more precise, we have a variable cifar10 which is a dataset containing tuples.\n",
    "\n",
    "These tuples are composed of :\n",
    "\n",
    "a tensor (which represents the image)\n",
    "an int which represents the label of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55395df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, int)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t, index_label = cifar10[5]\n",
    "type(img_t), type(index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19440171",
   "metadata": {},
   "source": [
    "We have recovered one of the images of the dataset, letâ€™s display it !\n",
    "\n",
    "We recall that an image tensor is in the format Color X Height X Width. To display the image, it is necessary to change its format to Height X Width X Color.\n",
    "\n",
    "To do so, we use the permute() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6532b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08afdb",
   "metadata": {},
   "source": [
    "We also may display the label associated with the image:\n",
    "\n",
    "The index_label variable is equal to 1. In fact we have retrieved the index that will allow us to know the name of the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53371a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6f947",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "Normalizing data is a step often forgotten by Data Scientists, even though it is essential to build a good Machine Learning algorithm.\n",
    "\n",
    "Normalization is the fact of modifying the data of each channel/tensor so that the mean is zero and the standard deviation is one.\n",
    "\n",
    "We show you an example with the normalization of a list below :\n",
    "\n",
    "We show you an example below with the normalization of a list belowâ€¦\n",
    "\n",
    "â€¦first, we calculate the mean and the standard deviation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba1eeee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8583670796659157, -0.8113997108400477, 0.6543546055161675, -0.5496578686335807, -0.07852255266194011, -1.0731415530465147]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "l = [60, 9, 37, 14, 23, 4]\n",
    "np.mean(l), np.std(l)\n",
    "\n",
    "l_norm = [(element - np.mean(l)) / np.std(l) for element in l]\n",
    "print(l_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8402f10",
   "metadata": {},
   "source": [
    "We can check that the mean is 0 and the standard deviation is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f41c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(l_norm), np.std(l_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d9fc9f",
   "metadata": {},
   "source": [
    "# The PyTorch advantage\n",
    "\n",
    "## Normalize Data Manually\n",
    "\n",
    "With PyTorch we can normalize our data set quite quickly.\n",
    "\n",
    "We are going to create the tensor channel we talked about in the previous part.\n",
    "\n",
    "To do this, we use the stack() function by indicating each of the tensors in our cifar10 variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc938ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "imgs = torch.stack([img_t for img_t, _ in cifar10], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d3abf",
   "metadata": {},
   "source": [
    "We obtain a channel that contains 50 000 images in 3x32x32 format.\n",
    "\n",
    "In fact this channel is a tensor. It is a tensor which contains other tensors ðŸ˜‰\n",
    "\n",
    "Thanks to this channel, we can calculate the average and standard deviation of all the tensors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "584ebd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = tensor([0.4914, 0.4822, 0.4465])\n",
      "std = tensor([0.2470, 0.2435, 0.2616])\n"
     ]
    }
   ],
   "source": [
    "print('mean = ' +  str(imgs.view(3, -1).mean(dim=1)))\n",
    "print('std = ' + str(imgs.view(3, -1).std(dim=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719ce68",
   "metadata": {},
   "source": [
    "No need to rewrite the normalization formula, the PyTorch library takes care of everything!\n",
    "\n",
    "We simply use the Normalize() function of the transforms module by indicating the mean and the standard deviation :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dc0ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28964cbd",
   "metadata": {},
   "source": [
    "We can then normalize all images of the channel at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58b9caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_norm = torch.stack([norm(img_t) for img_t, _ in cifar10], dim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6eb5e",
   "metadata": {},
   "source": [
    "Finally we can verify that our channel is well normalized with a mean of 0 and a standard deviation of 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f4c72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0007) tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(imgs_norm.mean(), imgs_norm.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82a944",
   "metadata": {},
   "source": [
    "## Barks audio normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c393971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dir = os.path.join(os.getcwd(), 'barks_10s')\n",
    "audio_path = os.path.join(audio_dir, 'bark_1.wav')\n",
    "\n",
    "audio, sample_rate = librosa.load(audio_path, res_type='kaiser_fast') \n",
    "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfcc_mean = np.mean(mfccs,axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30938e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CustomAudioDataset import CustomAudioDataset\n",
    "from utils.train_test_dataset import train_test_dataset\n",
    "\n",
    "annotation_file = os.path.join(os.getcwd(), 'barks_10s.csv')\n",
    "\n",
    "barks_dataset = CustomAudioDataset(annotations_file = annotation_file, audio_dir = audio_dir)    \n",
    "barks = torch.stack([barks_t for barks_t, _ in barks_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f02915a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([472, 40, 431])\n"
     ]
    }
   ],
   "source": [
    "print(barks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b86dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "barks_mean = np.mean(barks.cpu().detach().numpy(),axis=(0,2))\n",
    "barks_std = np.std(barks.cpu().detach().numpy(),axis=(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f580f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([472, 40, 431])\n"
     ]
    }
   ],
   "source": [
    "barks_norm = []\n",
    "\n",
    "for mfcc in range(barks.shape[1]):\n",
    "    #print(barks[:, mfcc, :].shape)\n",
    "    #print(barks_mean[mfcc])\n",
    "    #print(barks_std[mfcc])\n",
    "    barks_norm.append((barks[:, mfcc, :] - barks_mean[mfcc]) / barks_std[mfcc])\n",
    "\n",
    "barks_norm = torch.stack(barks_norm, dim=1)\n",
    "print(barks_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cba6a614",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4023097e-07\n",
      "0.9999997\n",
      "8.640787e-07\n",
      "0.9999998\n",
      "-3.1502868e-08\n",
      "0.9999999\n",
      "-2.9432678e-07\n",
      "1.0000001\n",
      "-1.5181382e-07\n",
      "0.9999999\n",
      "2.3702158e-08\n",
      "1.0000001\n",
      "-5.4004916e-09\n",
      "0.99999964\n",
      "-6.2795715e-07\n",
      "1.0\n",
      "-4.7164295e-07\n",
      "0.9999999\n",
      "3.1682885e-07\n",
      "1.0000001\n",
      "-2.0851898e-08\n",
      "0.9999999\n",
      "-7.2306584e-08\n",
      "1.0\n",
      "6.206815e-08\n",
      "0.9999998\n",
      "1.3351216e-07\n",
      "1.0\n",
      "-4.800437e-09\n",
      "1.0\n",
      "-1.0095919e-07\n",
      "0.9999998\n",
      "8.378262e-08\n",
      "1.0000002\n",
      "-5.5205025e-08\n",
      "1.0000001\n",
      "-2.3462135e-07\n",
      "0.9999998\n",
      "-4.7629335e-08\n",
      "0.9999999\n",
      "1.800164e-08\n",
      "1.0000001\n",
      "1.4101284e-08\n",
      "1.0\n",
      "1.0800983e-08\n",
      "1.0000001\n",
      "-3.1952908e-08\n",
      "1.0000002\n",
      "2.1001911e-08\n",
      "1.0\n",
      "-5.4004916e-09\n",
      "1.0000001\n",
      "-2.8202567e-08\n",
      "0.9999998\n",
      "-5.82053e-08\n",
      "0.99999994\n",
      "4.492909e-08\n",
      "1.0\n",
      "-3.7503414e-10\n",
      "1.0000001\n",
      "4.9504507e-08\n",
      "0.9999999\n",
      "3.000273e-10\n",
      "1.0000002\n",
      "-1.1566053e-07\n",
      "0.9999998\n",
      "-3.07528e-08\n",
      "1.0000001\n",
      "-1.3771253e-07\n",
      "0.9999999\n",
      "-7.4706804e-08\n",
      "0.99999976\n",
      "1.1566053e-07\n",
      "0.99999976\n",
      "7.110647e-08\n",
      "1.0\n",
      "-2.4842262e-07\n",
      "0.99999964\n",
      "2.4902267e-08\n",
      "0.9999998\n"
     ]
    }
   ],
   "source": [
    "for mfcc in range(barks_norm.shape[1]):\n",
    "    print(np.mean(barks_norm[:, mfcc, :].cpu().detach().numpy()))\n",
    "    print(np.std(barks_norm[:, mfcc, :].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88a648a0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n",
      "torch.Size([40, 431])\n"
     ]
    }
   ],
   "source": [
    "for sample in barks_norm:\n",
    "    print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d2bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NYUDL21",
   "language": "python",
   "name": "nyudl21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
