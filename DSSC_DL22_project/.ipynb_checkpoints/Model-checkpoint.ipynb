{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection with Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "from scipy.io import wavfile as wav\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract an MFCC for each cough audio file in the dataset and store it in a Panda Dataframe along with it's class label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfccs(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsnorm = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"file could not be loaded: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccsnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the path to the barks and not_barks datasets\n",
    "bark_folder = 'barks_10s'\n",
    "not_bark_folder = 'not_barks'\n",
    "bark_path = os.path.join(os.getcwd(), bark_folder)\n",
    "not_bark_path = os.path.join(os.getcwd(), not_bark_folder)\n",
    "\n",
    "csv_file = 'barks.csv'\n",
    "metadata = pd.read_csv(os.path.join(os.getcwd(),csv_file))\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    class_label = row[\"class_name\"]\n",
    "    \n",
    "    if class_label == 'bark':\n",
    "        file_name = os.path.join(os.path.abspath(bark_path),str(row[\"file_name\"]))\n",
    "    else:\n",
    "        file_name = os.path.join(os.path.abspath(not_bark_path),str(row[\"file_name\"]))\n",
    "    \n",
    "    data = extract_mfccs(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdataframe = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('features extracted from ', len(featuresdataframe), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featuresdataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barks_dataframe = featuresdataframe[featuresdataframe['class_label'] == 'bark']\n",
    "not_barks_dataframe = featuresdataframe[featuresdataframe['class_label'] == 'not_bark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the categorical text data into model-understandable numerical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and Class labels into numpy arrays\n",
    "X = np.array(barks_dataframe.feature.tolist())\n",
    "y = np.array(barks_dataframe.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "labelen = LabelEncoder()\n",
    "classen = to_categorical(labelen.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing sets. The testing set size will be 10% and we will set a random state. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, classen, test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train count: {len(x_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Autoencoder Model with L1 Sparsity Penalty as 1e-5 and Loss function as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activity_regularizer=l1(0.00001), activation='relu'))\n",
    "model.add(Dense(224, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(X.shape[1])) # Multiple output neurons\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train,x_train,verbose=1,epochs=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "#plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the MSE for the Test Dataset (out of sample) and on the Whole Dataset (In + Out Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(obs, preds):\n",
    "    count = 0\n",
    "\n",
    "    for prediction,observation in zip(preds,obs):\n",
    "        loss = np.sqrt(metrics.mean_squared_error(prediction,observation))\n",
    "        if loss < 1: count += 1 \n",
    "\n",
    "    accuracy = count / len(x_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Out of Sample Score (RMSE): 0.935054361820221\n",
      "Out of Sample accuracy: 0.6666666666666666\n",
      "Insample Normal Score (RMSE): 0.9366835355758667\n",
      "Insample accuracy): 6.583333333333333\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "score1 = np.sqrt(metrics.mean_squared_error(pred,x_test))\n",
    "accuracy1 = compute_acc(x_test,pred)\n",
    "pred = model.predict(X)\n",
    "score2 = np.sqrt(metrics.mean_squared_error(pred,X))\n",
    "accuracy2 = compute_acc(X,pred)\n",
    "\n",
    "print(f\"Out of Sample Score (RMSE): {score1}\")\n",
    "print(f\"Out of Sample accuracy: {accuracy1}\")\n",
    "print(f\"Insample Normal Score (RMSE): {score2}\")\n",
    "print(f\"Insample accuracy): {accuracy2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to predict the MSE for validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(not_barks_dataframe.feature[0:2])\n",
    "#print(np.array(not_barks_dataframe.feature[0:2])) \n",
    "#print(np.array(not_barks_dataframe.feature.tolist()[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_not_barks)\n",
    "print(compute_acc(X_not_barks, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 40)\n",
      "Validation sample (RMSE): 11.18336009979248\n"
     ]
    }
   ],
   "source": [
    "X_not_barks = np.array(not_barks_dataframe.feature.tolist())\n",
    "pred = model.predict(X_not_barks)\n",
    "score3 = np.sqrt(metrics.mean_squared_error(pred,X_not_barks))\n",
    "print(f\"Validation sample (RMSE): {score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\\\\\Documents\\\\Cough Detection\\\\Data\\\\autoencoder_model_4.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NYUDL21",
   "language": "python",
   "name": "nyudl21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
